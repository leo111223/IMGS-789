{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loading the CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "cifar10_data = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(cifar10_data, batch_size=128, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator class\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, 512, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, img_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Generator and Discriminator\n",
    "z_dim = 100\n",
    "img_channels = 3\n",
    "gen = Generator(z_dim, img_channels).to(device)\n",
    "disc = Discriminator(img_channels).to(device)\n",
    "\n",
    "# Optimizers and Loss function\n",
    "lr = 0.0002\n",
    "gen_opt = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "disc_opt = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the DCGAN\n",
    "epochs = 2\n",
    "fixed_noise = torch.randn(25, z_dim, 1, 1).to(device)\n",
    "g_losses, d_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    g_loss_epoch, d_loss_epoch = 0, 0\n",
    "    for real, _ in dataloader:\n",
    "        real = real.to(device)\n",
    "        batch_size = real.size(0)\n",
    "\n",
    "        # Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "\n",
    "        disc_opt.zero_grad()\n",
    "        lossD.backward()\n",
    "        disc_opt.step()\n",
    "\n",
    "        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z)))\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "\n",
    "        gen_opt.zero_grad()\n",
    "        lossG.backward()\n",
    "        gen_opt.step()\n",
    "\n",
    "        g_loss_epoch += lossG.item()\n",
    "        d_loss_epoch += lossD.item()\n",
    "\n",
    "    # Save losses\n",
    "    g_losses.append(g_loss_epoch / len(dataloader))\n",
    "    d_losses.append(d_loss_epoch / len(dataloader))\n",
    "\n",
    "    # Visualize progress every 10 epochs\n",
    "    if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "        with torch.no_grad():\n",
    "            fake_images = gen(fixed_noise).cpu()\n",
    "            grid = torchvision.utils.make_grid(fake_images, nrow=5, normalize=True)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "            plt.title(f\"Epoch {epoch}\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] | Loss D: {d_losses[-1]:.4f}, Loss G: {g_losses[-1]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Loss Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(g_losses, label=\"Generator Loss\")\n",
    "plt.plot(d_losses, label=\"Discriminator Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Generator and Discriminator Loss Curves\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize Generated Images\n",
    "with torch.no_grad():\n",
    "    fake_images = gen(fixed_noise).cpu()\n",
    "    grid = torchvision.utils.make_grid(fake_images, nrow=5, normalize=True)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    plt.title(\"Generated Images after Training\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Real CIFAR-10 Images\n",
    "real_images, _ = next(iter(dataloader))\n",
    "real_images = real_images[:25]\n",
    "real_grid = torchvision.utils.make_grid(real_images, nrow=5, normalize=True)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(np.transpose(real_grid, (1, 2, 0)))\n",
    "plt.title(\"Real CIFAR-10 Images\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Comment on Generated Images\n",
    "print(\"The generated images resemble the CIFAR-10 dataset, showcasing the ability of the DCGAN to learn complex image structures.\"\n",
    "      \" While some generated images are more realistic, there is still variability in quality, indicating areas for further training or model adjustment.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
